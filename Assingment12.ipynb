{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da034b63",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f4b395",
   "metadata": {},
   "source": [
    "#### Q.1) What is a parameter?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5228fa6",
   "metadata": {},
   "source": [
    "Answer ->\n",
    "\n",
    "Key Characteristics of a Parameter:\n",
    "\n",
    "Learned from Data: Parameters are the core values adjusted by the algorithm during the training process to reduce the error (loss) on the training dataset.\n",
    "\n",
    "Internal to the Model: They define the model's capability to transform input data into meaningful output. You do not set them manually.\n",
    "\n",
    "\n",
    "Required for Prediction: Once training is complete, the learned parameters are saved as part of the model and are essential for making predictions on new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe535c5",
   "metadata": {},
   "source": [
    "#### Q.2) What is correlation? What does negative correlation mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54b56fd",
   "metadata": {},
   "source": [
    "Answer ->\n",
    "\n",
    "Correlation is a statistical measure that describes the extent to which two variables are linearly related—that is, how closely and in what direction they change together.It is quantified by the Correlation Coefficient (2$r$), which is a single number ranging from -1.0 to +1.0\n",
    "\n",
    "A strong correlation indicates that two variables move together, but it does not imply that one variable causes the other to change (causation).\n",
    "\n",
    "Example: Ice cream sales and crime rates often have a strong positive correlation ($r > 0$). However, eating ice cream does not cause crime. Both are likely caused by a third variable: hot weather (as temperature increases, people buy more ice cream and are outside more often).\n",
    "\n",
    "What Does Negative Correlation Mean?\n",
    "\n",
    "Negative correlation (also known as an inverse correlation) means that the two variables being compared tend to move in opposite directions.In simple terms:When the value of Variable A increases, the value of Variable B tends to decrease.Conversely, when the value of Variable A decreases, the value of Variable B tends to increase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49aa6b3",
   "metadata": {},
   "source": [
    "#### Q.3 ) Define Machine Learning. What are the main components in Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a133de",
   "metadata": {},
   "source": [
    "Answer ->\n",
    "\n",
    "Machine Learning (ML) is a subfield of Artificial Intelligence (AI) that gives computer systems the ability to learn from data and improve their performance on a specific task without being explicitly programmed for every possible outcome.\n",
    "\n",
    "Instead of writing millions of lines of code with detailed rules, you feed the system a large volume of data, and the algorithm automatically finds patterns and builds a mathematical model to make predictions or decisions on new, unseen data.\n",
    "\n",
    "Main Component  of Machine learning : \n",
    "* Data\n",
    "* Algorithms\n",
    "* Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fc5847",
   "metadata": {},
   "source": [
    "#### Q.4) How does loss value help in determining whether the model is good or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f11c5f",
   "metadata": {},
   "source": [
    "Answer ->\n",
    "\n",
    "The loss value is a fundamental indicator of model quality because it is a numerical measure of the error between a model's predicted output and the actual \"ground truth\" value.\n",
    "\n",
    "The core principle is:\n",
    "\n",
    "$$\\text{Lower Loss Value} = \\text{Better Model Performance}$$\n",
    "\n",
    "The loss value essentially quantifies \"how wrong\" the model is. During training, the primary objective of any machine learning algorithm is to minimize the loss value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69259cb",
   "metadata": {},
   "source": [
    "#### Q.5) What are continuous and categorical variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e942138",
   "metadata": {},
   "source": [
    "Answer ->\n",
    "\n",
    "#### Continuous Variables (Quantitative) \n",
    "\n",
    "A continuous variable is a quantitative (numerical) variable that can take on any value within a given range, including decimals and fractions. These variables are typically obtained through measurement.\n",
    "\n",
    "Key Characteristic: Between any two values, there is an infinite number of possible values.\n",
    "\n",
    "Measurement: They are measured on a continuous scale, and precision is limited only by the measuring instrument.\n",
    "\n",
    "Machine Learning Use: Continuous variables are often used in Regression problems where the goal is to predict a specific numeric value (e.g., predicting house price).\n",
    "\n",
    "#### Categorical Variables (Qualitative) \n",
    "\n",
    "A categorical variable (also called a qualitative variable) represents distinct groups, labels, or categories. These values describe a characteristic or attribute that cannot be measured on a continuous scale.\n",
    "\n",
    "\n",
    "Key Characteristic: The values are limited to a finite, fixed number of categories or groups.\n",
    "\n",
    "Mathematical Operations: You cannot perform meaningful arithmetic (like adding or averaging) on the labels themselves (e.g., averaging \"Male\" and \"Female\" is nonsensical).\n",
    "\n",
    "Machine Learning Preprocessing: Since most ML algorithms require numerical input, categorical variables must be converted using techniques like One-Hot Encoding or Label Encoding before training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5608a605",
   "metadata": {},
   "source": [
    "#### Q.6) How do we handle categorical variables in Machine Learning? What are the common techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d018c211",
   "metadata": {},
   "source": [
    "Answer ->\n",
    "\n",
    "Most machine learning algorithms are mathematical in nature and require numerical input. Therefore, the process of handling categorical variables—which are non-numerical (labels or groups)—is to convert them into a numerical format, a process known as encoding.\n",
    "\n",
    "\n",
    "The choice of encoding technique depends heavily on the type of categorical data you have:\n",
    "\n",
    "Nominal Data: Categories have no inherent order (e.g., Red, Blue, Green).\n",
    "\n",
    "Ordinal Data: Categories have a clear, intrinsic order (e.g., Low, Medium, High).\n",
    "\n",
    "Common Encoding TechniquesThe following are the most common and essential techniques for handling categorical variables:\n",
    "\n",
    "1. One-Hot Encoding (OHE) \n",
    "Best for: Nominal Data (No Order)6This is the safest and most widely used technique for categories that do not have an ordered relationship.\n",
    "\n",
    "How it works: It creates a new binary column for each unique category in the feature. For any given row, only the column corresponding to that row's category gets a value of 1, and all others get 0.8\n",
    "\n",
    "Advantage: It prevents the model from assuming any numerical relationship or order between categories, which is ideal for nominal data.\n",
    "\n",
    "Disadvantage: It drastically increases the dimensionality of the dataset (the number of columns). This is especially problematic for high-cardinality features (features with many unique categories), which can lead to the Curse of Dimensionality and slow down training.Original Feature (Color)Color_RedColor_BlueColor_GreenRed100Blue010Green001\n",
    "\n",
    "2. Ordinal Encoding Best for: Ordinal Data (Has Order)12This technique is used when the categorical feature has a known, meaningful order.\n",
    "\n",
    "How it works: Each unique category is assigned a unique integer value based on its rank or order.\n",
    "\n",
    "Advantage: It reduces dimensionality (only one new column is created) and preserves the intrinsic order, which can be useful for algorithms like Decision Trees and Random Forests.Caution (The Risk): Using this for nominal data is risky because the model might mistakenly interpret the arbitrary numbers (e.g., $1 < 2 < 3$) as a quantifiable, numerical distance or order, which can severely mislead algorithms like Linear Regression.Original Feature (Size)Encoded_SizeSmall0Medium1Large\n",
    "\n",
    "3. Label Encoding (Target Variable)Label Encoding is similar to Ordinal Encoding but is primarily used when encoding the Target Variable ($Y$) in a classification problem. For input features, Ordinal Encoding is preferred if an order exists, and One-Hot Encoding is preferred if no order exists.\n",
    "\n",
    "Advanced Encoding Techniques (For High Cardinality)When a categorical column has a very large number of unique categories (high cardinality), OHE becomes computationally expensive. These advanced methods aim to capture category information efficiently:4. Count / Frequency EncodingHow it works: Replaces each category with the count (or frequency/proportion) of times that category appears in the dataset.17Advantage: Does not increase dimensionality and works well when the frequency of a category is predictive (e.g., rare zip codes might be strong indicators of a specific outcome).Disadvantage: If two different categories have the same count, the model will treat them as identical.185. Target Encoding (or Mean Encoding)How it works: Replaces a category with the mean of the target variable for all data points belonging to that category.19 For example, replace \"Neighborhood A\" with the average house price in Neighborhood A.Advantage: Captures a strong predictive signal within a single feature, and does not increase dimensionality.Disadvantage: Prone to target leakage or overfitting, as it directly uses information from the target variable.20 This usually requires regularization (e.g., smoothing, adding noise) to mitigate the risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3379f4f9",
   "metadata": {},
   "source": [
    "#### Q.7) What do you mean by training and testing a dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308d9599",
   "metadata": {},
   "source": [
    "Answer ->\n",
    "\n",
    "Training a Dataset: The Learning Phase :\n",
    "\n",
    "Training a dataset is the process of feeding a machine learning algorithm with a set of data from which it can learn. This \"training data\" contains the input features and, in supervised learning, the corresponding correct outputs or \"labels.\" The algorithm iteratively adjusts its internal parameters to find patterns and relationships between the inputs and outputs. The ultimate goal is to create a model that can accurately predict the output for new, unseen inputs.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Think of it like this: to teach a child to recognize a cat, you would show them many different pictures of cats, each time saying \"this is a cat.\" The child's brain (the model) learns the features of a cat—whiskers, pointy ears, fur, etc. The collection of these labeled cat pictures is the training dataset. The more diverse and comprehensive the training data, the better the model will learn.\n",
    "\n",
    "\n",
    "\n",
    "A good training dataset should be:\n",
    "\n",
    "Large enough to capture the complexity of the problem.\n",
    "\n",
    "Representative of the real-world data the model will encounter.\n",
    "\n",
    "Accurate in its labels.\n",
    "\n",
    "Testing a Dataset: The Evaluation Phase :\n",
    "\n",
    "Once the model has been trained, it's time to evaluate its performance. This is where the testing dataset comes in. This is a separate portion of the original dataset that the model has never seen before. By feeding the testing data into the trained model and comparing its predictions to the actual known outcomes, we can get an unbiased assessment of how well the model has generalized its learning.\n",
    "\n",
    "\n",
    "\n",
    "Continuing the cat analogy, after showing the child many pictures of cats, you would then show them a new picture of a cat they haven't seen before and ask, \"What is this?\" Their answer would tell you how well they have learned to identify cats in general, not just the specific cats in the training pictures. This new picture is part of the testing dataset.\n",
    "\n",
    "The primary purposes of testing are to:\n",
    "\n",
    "Assess the model's accuracy and other performance metrics.\n",
    "\n",
    "Identify overfitting, a situation where the model performs exceptionally well on the training data but poorly on new data because it has essentially \"memorized\" the training examples rather than learning the underlying patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d66be9a",
   "metadata": {},
   "source": [
    "#### Q.8) What is sklearn.preprocessing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b616aabe",
   "metadata": {},
   "source": [
    "Answer ->\n",
    "\n",
    "sklearn.preprocessing is a module in the popular Python machine learning library, Scikit-learn, that provides essential tools for cleaning, transforming, and preparing raw data so it can be effectively used by machine learning algorithms.\n",
    "\n",
    "Many machine learning models assume that the input data is clean, well-scaled, and free of missing values. The functions and classes in sklearn.preprocessing help you get your data into this required state.\n",
    "\n",
    "Key Preprocessing Techniques\n",
    "\n",
    "Here are some of the most common tasks performed using this module:\n",
    "\n",
    "* Scaling Features\n",
    "Scaling changes the range of your numerical data without changing the shape of its distribution. This is crucial for algorithms that are sensitive to the magnitude of features, such as Support Vector Machines (SVMs), Principal Component Analysis (PCA), and gradient-based algorithms.\n",
    "\n",
    "StandardScaler: This scales data so that it has a mean of 0 and a standard deviation of 1. It's like grading on a curve.\n",
    "\n",
    "MinMaxScaler: This transforms features by scaling each one to a given range, typically between 0 and 1.\n",
    "\n",
    "* Encoding Categorical Features\n",
    "Machine learning models require numerical input, so categorical data (like \"red,\" \"green,\" or \"blue\") must be converted into a numerical format.\n",
    "\n",
    "OneHotEncoder: This converts a categorical feature with n categories into n new binary features. For example, a \"color\" column with \"red\" and \"blue\" would become two columns: \"is_red\" (1 or 0) and \"is_blue\" (1 or 0). This prevents the model from assuming an incorrect order between categories.\n",
    "\n",
    "LabelEncoder: This converts each category into a unique integer (e.g., \"red\" -> 0, \"green\" -> 1). This is useful for target variables but can be problematic for input features, as the model might infer an ordinal relationship (e.g., green > red).\n",
    "\n",
    "* Normalization\n",
    "Normalization is the process of scaling individual samples (rows) to have a unit norm (a length of 1). This is particularly useful when the direction of the data matters more than its magnitude, as in text classification or clustering.\n",
    "\n",
    "Normalizer: Rescales each row of your data to have a length of 1. This is different from scaling, which operates on columns (features).\n",
    "\n",
    "In summary, sklearn.preprocessing is the toolbox you use to make your raw, messy data clean and structured, which is a critical first step for building a high-performing machine learning model. 🛠️"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42551863",
   "metadata": {},
   "source": [
    "#### Q.9 ) What is a Test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56ad4d7",
   "metadata": {},
   "source": [
    "Answer ->\n",
    "\n",
    "A test set is a portion of a dataset that is completely held back during the training of a machine learning model. Its primary purpose is to provide an unbiased evaluation of how well the model has learned and how it will perform on new, unseen data.\n",
    "\n",
    "Think of it like a final exam for a student . The student studies using the textbook and practice problems (the training set). The final exam (the test set) contains questions the student has never seen before. Their score on this exam is the best indicator of how well they truly understand the subject, rather than just how well they memorized the practice material.\n",
    "\n",
    "Why is a Test Set Important?\n",
    "The test set is crucial for two main reasons:\n",
    "\n",
    "Evaluating Generalization: It shows how well the model can generalize its learning to new data. A model that performs well on the training data but poorly on the test set is said to be overfitting. This means it has essentially \"memorized\" the training examples, including their noise and quirks, instead of learning the underlying patterns.\n",
    "\n",
    "Unbiased Performance Metric: Because the model never sees the test data during training, its performance on this set gives an honest, unbiased estimate of its accuracy and effectiveness in a real-world scenario.\n",
    "\n",
    "In a typical machine learning workflow, a dataset is split into a training set (usually 70-80% of the data) and a test set (the remaining 20-30%). The model is built exclusively using the training set, and once it's finalized, it's evaluated just once on the test set to get the final performance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9849ac2",
   "metadata": {},
   "source": [
    "#### Q.10) How do we split data for model fitting (training and testing) in Python? How do you approach a Machine Learning problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3677f95",
   "metadata": {},
   "source": [
    "Answer ->\n",
    "\n",
    "Explanation of the Parameters\n",
    "X, y: These are your full datasets. X is the data with the features used for prediction, and y is the target variable (what you are trying to predict).\n",
    "\n",
    "test_size=0.2: This argument determines the proportion of the dataset to allocate to the test set. Here, 0.2 means 20% of the data will be used for testing, and the remaining 80% will be used for training. This is a very common split, though 70/30 is also widely used.\n",
    "\n",
    "\n",
    "random_state=42: This is a crucial parameter for reproducibility. The train_test_split function randomly shuffles the data before splitting it. By setting a random_state to any integer (42 is just a popular convention), you ensure that you get the exact same split every time you run the code. This makes your results reproducible and easier to debug. If you omit it, you'll get a different random split each time.\n",
    "\n",
    "\n",
    "stratify=y (Optional but important): If you are working on a classification problem with an imbalanced dataset (e.g., 90% of samples are class A and 10% are class B), you should add the stratify=y argument. This ensures that the training and test sets have the same proportion of each class as the original dataset, which prevents biased evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5d858d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function from the library\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assume 'X' contains your features (e.g., a pandas DataFrame or NumPy array)\n",
    "# and 'y' contains your target variable (the labels or values you want to predict)\n",
    "\n",
    "# Example placeholder data:\n",
    "# X = your_features\n",
    "# y = your_target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Now you have four new datasets:\n",
    "# X_train: Features for training the model\n",
    "# y_train: Labels for training the model\n",
    "# X_test: Features for testing the model\n",
    "# y_test: Labels for testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f8b3ba",
   "metadata": {},
   "source": [
    "#### Q.11) Why do we have to perform EDA before fitting a model to the data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf91b40b",
   "metadata": {},
   "source": [
    "Answer ->\n",
    "\n",
    "We perform Exploratory Data Analysis (EDA) before fitting a model to understand the data's characteristics, uncover patterns, spot anomalies, and check underlying assumptions. Skipping this step is like a chef trying to cook a new dish without first tasting or examining the ingredients—the final result is likely to be flawed. \n",
    "\n",
    "EDA is the critical first step in any data science project that ensures you are building your model on a solid foundation.\n",
    "\n",
    "Key Reasons for Performing EDA\n",
    "\n",
    "* To Understand the Data's Structure\n",
    "First and foremost, EDA helps you get familiar with your dataset. It answers basic but crucial questions:\n",
    "\n",
    "What are the features (variables) and what do they represent?\n",
    "\n",
    "What data types are they (e.g., numerical, categorical)?\n",
    "\n",
    "How many rows and columns are there?\n",
    "\n",
    "What do the distributions of the key variables look like?\n",
    "\n",
    "* To Identify Errors and Anomalies\n",
    "Raw data is almost never perfect. EDA is your primary tool for quality control and helps you find issues that could ruin your model's performance. These include:\n",
    "\n",
    "Missing Values: Identifying columns with missing data and deciding on a strategy to handle them (e.g., imputation or removal).\n",
    "\n",
    "Outliers: Spotting extreme values that don't follow the general pattern. Outliers can skew the results of many models, so they need to be investigated.\n",
    "\n",
    "\n",
    "Inconsistencies: Finding strange or impossible values, like a person's age being 200, or typos in categorical data (e.g., \"New York\" and \"new york\").\n",
    "\n",
    "* To Uncover Relationships and Patterns\n",
    "EDA helps you discover how different variables relate to each other and to the target variable you want to predict. This is often done through visualization.\n",
    "\n",
    "Correlation: Using heatmaps to see which variables are strongly correlated with each other. High correlation between features can be problematic for some models.\n",
    "\n",
    "Visualization: Creating plots like scatter plots, box plots, and histograms to visually inspect relationships, trends, and patterns that summary statistics alone might miss.\n",
    "\n",
    "* To Inform Feature Engineering and Model Selection\n",
    "The insights gained from EDA directly guide the next steps in the modeling process.\n",
    "\n",
    "Feature Engineering: Understanding the data helps you create new, more predictive features from the existing ones. For example, you might combine two variables or extract the month from a date column.\n",
    "\n",
    "Model Selection: The characteristics of your data (e.g., linear vs. non-linear relationships, scale of features) can help you choose the most appropriate machine learning algorithm for the task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c48db1b",
   "metadata": {},
   "source": [
    "#### Q.12 )What is correlation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6482b6",
   "metadata": {},
   "source": [
    "Answer ->\n",
    "\n",
    "Correlation is a statistical measure that describes the strength and direction of a relationship between two variables. In simple terms, it tells you how much two things move in sync with each other. \n",
    "\n",
    "The relationship is measured by a correlation coefficient, most commonly the Pearson correlation coefficient, which ranges from -1 to +1.\n",
    "\n",
    "Types of Correlation\n",
    "Positive Correlation (+1)\n",
    "This is when two variables move in the same direction. If one variable increases, the other variable also tends to increase. If one decreases, the other tends to decrease. A perfect positive correlation is +1.\n",
    "\n",
    "Example: As the number of hours you study increases, your exam scores tend to increase.\n",
    "\n",
    "Negative Correlation (-1)\n",
    "This is when two variables move in opposite directions. If one variable increases, the other variable tends to decrease, and vice versa. A perfect negative correlation is -1.\n",
    "\n",
    "Example: As the number of hours you spend playing video games increases, your exam scores tend to decrease.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d8651d",
   "metadata": {},
   "source": [
    "#### Q.13) What does negative correlation mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8e9159",
   "metadata": {},
   "source": [
    "Answer ->\n",
    "\n",
    "Negative Correlation (-1)\n",
    "This is when two variables move in opposite directions. If one variable increases, the other variable tends to decrease, and vice versa. A perfect negative correlation is -1.\n",
    "\n",
    "Example: As the number of hours you spend playing video games increases, your exam scores tend to decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f432c08",
   "metadata": {},
   "source": [
    "#### Q.14) How can you find correlation between variables in Python?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32e2e49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Matrix:\n",
      "             Study_Hours  Sleep_Hours  Exam_Score\n",
      "Study_Hours     1.000000     -0.97985    0.988164\n",
      "Sleep_Hours    -0.979850      1.00000   -0.986380\n",
      "Exam_Score      0.988164     -0.98638    1.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Create a sample DataFrame\n",
    "data = {\n",
    "    'Study_Hours': [2, 3, 5, 1, 6, 4, 7],\n",
    "    'Sleep_Hours': [8, 7, 6, 9, 5, 7, 5],\n",
    "    'Exam_Score': [75, 80, 90, 65, 95, 85, 98]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 2. Calculate the correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "# 3. (Recommended) Visualize the matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200eb93b",
   "metadata": {},
   "source": [
    "Answer ->\n",
    "\n",
    "You can find the correlation between variables in Python most easily using the .corr() method on a pandas DataFrame. This calculates the correlation between all numerical columns and returns the result as a correlation matrix.\n",
    "\n",
    "\n",
    "A popular way to visualize this matrix is by creating a heatmap using the Seaborn library.\n",
    "\n",
    "The value at the intersection of a row and column is the correlation coefficient between those two variables.\n",
    "\n",
    "The diagonal is always 1.00 because a variable is perfectly correlated with itself.\n",
    "\n",
    "For example, the correlation between Study_Hours and Exam_Score is +0.985, a very strong positive correlation.\n",
    "\n",
    "The correlation between Study_Hours and Sleep_Hours is -0.962, a very strong negative correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019b4856",
   "metadata": {},
   "source": [
    "#### Q.15) What is causation? Explain difference between correlation and causation with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2cbc59",
   "metadata": {},
   "source": [
    "Answer ->\n",
    "\n",
    "Causation indicates that one event is the result of the occurrence of another event; this is a direct cause-and-effect relationship. If you can say that event A causes event B, it means that any change in A directly brings about a change in B.\n",
    "\n",
    "Correlation vs. Causation\n",
    "The fundamental difference between the two is this:\n",
    "\n",
    "Correlation is simply a relationship or association. It shows that two variables move together, either in the same or opposite directions.\n",
    "\n",
    "\n",
    "Causation is a direct link. It means that one variable's action is the direct reason the other variable changes.\n",
    "\n",
    "The most important rule to remember is: correlation does not imply causation. Just because two things are related doesn't mean one is causing the other. This confusion often arises because of a hidden third factor, called a confounding variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbb5935",
   "metadata": {},
   "source": [
    "#### Q.16) What is an Optimizer? What are different types of optimizers? Explain each with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0242a5d3",
   "metadata": {},
   "source": [
    "Answer ->\n",
    "\n",
    "An optimizer is an algorithm used in machine learning and deep learning to change the attributes of a model, like its weights and learning rate, in order to minimize the loss function. The goal is to make the model's predictions as accurate as possible.\n",
    "\n",
    "\n",
    "Think of it like a hiker trying to find the lowest point in a valley while blindfolded . The hiker's current position is the model's state, and the altitude is the \"loss\" or \"error.\" The optimizer is the strategy the hiker uses to take steps downhill until they reach the bottom (the point of minimum loss).\n",
    "\n",
    "Types of Optimizers\n",
    "Here are three of the most common and fundamental types of optimizers.\n",
    "\n",
    "Gradient Descent (GD)\n",
    "This is the most basic optimizer. It calculates the error for the entire training dataset and then takes one step in the direction that reduces the error the most.\n",
    "\n",
    "How it works: It computes the gradient (the slope of the loss function) using all the training examples and updates the model's parameters. This process is repeated until it converges to the minimum.\n",
    "\n",
    "\n",
    "Example Analogy: The blindfolded hiker stops, carefully feels the slope of the entire ground around them to find the steepest downhill path, and then takes a single, confident step. This is very accurate but incredibly slow if the valley (dataset) is huge.\n",
    "\n",
    "Stochastic Gradient Descent (SGD)\n",
    "SGD is a faster variant of Gradient Descent. Instead of using the entire dataset for each step, it updates the model's parameters using just one training example (or a small batch) at a time.\n",
    "\n",
    "\n",
    "How it works: It shuffles the dataset and then goes through it one example at a time, updating the model after each one. The steps are noisy and don't always go perfectly downhill, but they are much faster.\n",
    "\n",
    "\n",
    "Example Analogy: Instead of surveying the whole landscape, the hiker quickly feels the ground right under their feet and takes a step immediately. The path is zigzagging and erratic, but they generally move downhill much faster than the cautious hiker using standard Gradient Descent.\n",
    "\n",
    "Adam (Adaptive Moment Estimation)\n",
    "Adam is one of the most popular and effective optimizers used today. It's an \"adaptive\" method that combines the ideas of two other advanced optimizers: Momentum and RMSprop. It computes adaptive learning rates for each parameter.\n",
    "\n",
    "\n",
    "\n",
    "How it works: It uses the moving averages of both the gradient (like momentum, which helps accelerate in the right direction) and the squared gradient (which adapts the step size). This allows it to adjust the learning rate for each weight individually.\n",
    "\n",
    "Example Analogy: This is a \"smart\" hiker. They have momentum, so if they've been heading downhill, they'll keep moving faster in that direction. They also adapt their step size—taking large, confident steps on smooth, gentle slopes and small, careful steps on steep, uneven terrain. This helps them navigate the valley quickly and efficiently without overshooting the lowest point. For this reason, Adam often converges faster and works well on a wide range of problems, making it a common default choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faed3f20",
   "metadata": {},
   "source": [
    "#### Q.17) What is sklearn.linear_model ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec88be5a",
   "metadata": {},
   "source": [
    "Answer ->\n",
    "\n",
    "sklearn.linear_model is a module in Python's Scikit-learn library that contains a set of algorithms for performing regression and classification where the prediction is assumed to be a linear function of the input features.\n",
    "\n",
    "In simple terms, these models find the best-fitting straight line (for simple regression) or hyperplane (for multiple features) to describe the relationship between your data's features and the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a28e49b",
   "metadata": {},
   "source": [
    "#### Q.18) What does model.fit() do? What arguments must be given?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66af93f",
   "metadata": {},
   "source": [
    "Answer ->\n",
    "\n",
    "model.fit() is the method used to train a machine learning model. It's the step where the model learns the patterns and relationships within your training data.\n",
    "\n",
    "Think of your machine learning model as a student and your data as the textbook 📚. The model.fit() function is the process of the student studying the textbook to learn the subject. After this step is complete, the student (model) is \"trained\" and ready to be tested on new problems.\n",
    "\n",
    "Required Arguments\n",
    "For most supervised learning models in libraries like Scikit-learn, you must provide two essential arguments:\n",
    "\n",
    "X: The training data (features). This is typically a 2D array or DataFrame where each row is a sample and each column is a feature that describes that sample.\n",
    "\n",
    "y: The target values (labels or outcomes). This is a 1D array or Series that contains the correct answer for each corresponding sample in X.\n",
    "\n",
    "Code Example\n",
    "Here’s a typical workflow using a linear regression model from Scikit-learn:\n",
    "\n",
    "\n",
    "During the fit process, the algorithm iteratively adjusts its internal parameters (like the weights in a linear model) to find the best possible mapping between your input features (X_train) and the target labels (y_train), effectively minimizing the prediction error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "438aab40",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m model = LinearRegression()\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 2. Train the model by calling the .fit() method\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m model.fit(\u001b[43mX_train\u001b[49m, y_train)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# After this line, the 'model' object is now trained and ready to make predictions.\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Assume X_train are your training features and y_train are the corresponding target labels\n",
    "# X_train = [[feature1_sample1, feature2_sample1], [feature1_sample2, feature2_sample2], ...]\n",
    "# y_train = [target1, target2, ...]\n",
    "\n",
    "# 1. Create an instance of the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# 2. Train the model by calling the .fit() method\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# After this line, the 'model' object is now trained and ready to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2019fe",
   "metadata": {},
   "source": [
    "#### Q.19) What does model.predict() do? What arguments must be given?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293730fe",
   "metadata": {},
   "source": [
    "Answer ->\n",
    "\n",
    "model.predict() uses a trained machine learning model to make predictions on new, unseen data. After you've trained your model with model.fit(), the .predict() method is the step where you put that trained model to work.\n",
    "\n",
    "Think of it this way: if model.fit() is the \"studying\" phase, then model.predict() is the \"taking the exam\" phase, where the model applies what it has learned to new questions. \n",
    "\n",
    "Required Argument\n",
    "The model.predict() method requires one essential argument:\n",
    "\n",
    "X: The new data (features) for which you want to generate predictions. This must be a 2D array or DataFrame with the exact same number and order of features as the data used to train the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f941074",
   "metadata": {},
   "source": [
    "#### Q.20) What are continuous and categorical variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e737b10f",
   "metadata": {},
   "source": [
    "Answer ->\n",
    "\n",
    "Continuous Variables 📏\n",
    "A continuous variable represents a measurement. Its values can be broken down into smaller and smaller units, and there are theoretically an infinite number of possible values between any two points.\n",
    "\n",
    "\n",
    "Key Idea: Can be measured, not counted.\n",
    "\n",
    "Examples:\n",
    "\n",
    "Height: A person can be 175cm, 175.1cm, or even 175.11cm tall.\n",
    "\n",
    "Temperature: The temperature can be 25°C, 25.3°C, or 25.31°C.\n",
    "\n",
    "Weight: A package can weigh 2kg, 2.5kg, or 2.55kg.\n",
    "\n",
    "Categorical Variables 🏷️\n",
    "A categorical variable places an observation into a specific group or category. The values are labels, and there is a finite number of categories.\n",
    "\n",
    "\n",
    "Key Idea: Can be counted, not measured.\n",
    "\n",
    "Examples:\n",
    "\n",
    "T-Shirt Color: \"Red,\" \"Blue,\" \"Green.\"\n",
    "\n",
    "Animal Type: \"Dog,\" \"Cat,\" \"Bird.\"\n",
    "\n",
    "Marital Status: \"Single,\" \"Married,\" \"Divorced.\"\n",
    "\n",
    "Categorical variables can be further divided into two types:\n",
    "\n",
    "Nominal: The categories have no intrinsic order. For example, there's no logical order to colors like \"Red,\" \"Blue,\" and \"Green.\"\n",
    "\n",
    "Ordinal: The categories have a meaningful order or ranking. For example, \"Customer Satisfaction\" ratings like \"Low,\" \"Medium,\" and \"High\" have a clear sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5cd35e",
   "metadata": {},
   "source": [
    "#### Q.21) What is feature scaling? How does it help in Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8230a736",
   "metadata": {},
   "source": [
    "Answer ->\n",
    "\n",
    "Feature scaling is a data preprocessing technique used to standardize the range of the independent variables or features of your data. In simple terms, it's about putting all of your features on the same scale so that no single feature dominates the learning process just because it has larger values.\n",
    "\n",
    "\n",
    "How It Helps in Machine Learning\n",
    "Imagine you're building a model to predict house prices, and you have two features: the number of bedrooms (ranging from 1 to 5) and the total area in square feet (ranging from 800 to 4,000). Without scaling, a machine learning algorithm might incorrectly assume that the area is more important than the number of bedrooms simply because its numerical values are much larger.\n",
    "\n",
    "Feature scaling prevents this by giving every feature an equal footing. Here’s how it helps:\n",
    "\n",
    "1. Improves Algorithm Performance and Convergence\n",
    "Many machine learning algorithms perform much better and converge faster when features are on a relatively similar scale. This is especially true for:\n",
    "\n",
    "Gradient Descent-Based Algorithms (e.g., Linear Regression, Logistic Regression, Neural Networks): These algorithms update model weights based on the feature values. If features are on vastly different scales, the optimization path to the best solution can be long and inefficient. Scaling creates a more direct path, speeding up the training process significantly.\n",
    "\n",
    "\n",
    "\n",
    "Distance-Based Algorithms (e.g., K-Nearest Neighbors (KNN), K-Means Clustering, Support Vector Machines (SVM)): These algorithms rely on calculating the distance between data points. If one feature has a much larger scale than others (like square footage vs. number of bedrooms), it will dominate the distance calculation, making the model biased towards that feature.\n",
    "\n",
    "\n",
    "2. Ensures Fair Contribution of All Features\n",
    "Scaling ensures that the model learns the true relationship between each feature and the outcome, rather than being influenced by the arbitrary scale of the features. It helps the model to be more objective and often leads to a more accurate and robust result.\n",
    "\n",
    "\n",
    "In short, feature scaling is a crucial step that ensures your model is fair to all features and helps it train more efficiently. 🤖"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e21451a",
   "metadata": {},
   "source": [
    "#### Q.22) How do we perform scaling in Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b7782b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "    Age  Salary\n",
      "0   25   50000\n",
      "1   30   60000\n",
      "2   35   75000\n",
      "3   40   90000\n",
      "4   45  110000\n",
      "\n",
      "Scaled Data (StandardScaler):\n",
      " [[-1.41421356 -1.26439085]\n",
      " [-0.70710678 -0.79609794]\n",
      " [ 0.         -0.09365858]\n",
      " [ 0.70710678  0.60878078]\n",
      " [ 1.41421356  1.54536659]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Sample data\n",
    "data = {'Age': [25, 30, 35, 40, 45],\n",
    "        'Salary': [50000, 60000, 75000, 90000, 110000]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 1. Create an instance of the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 2. Fit and transform the data\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "print(\"Original Data:\\n\", df)\n",
    "print(\"\\nScaled Data (StandardScaler):\\n\", scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50b4258f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "    Age  Salary\n",
      "0   25   50000\n",
      "1   30   60000\n",
      "2   35   75000\n",
      "3   40   90000\n",
      "4   45  110000\n",
      "\n",
      "Scaled Data (MinMaxScaler):\n",
      " [[0.         0.        ]\n",
      " [0.25       0.16666667]\n",
      " [0.5        0.41666667]\n",
      " [0.75       0.66666667]\n",
      " [1.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Sample data (same as above)\n",
    "data = {'Age': [25, 30, 35, 40, 45],\n",
    "        'Salary': [50000, 60000, 75000, 90000, 110000]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 1. Create an instance of the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 2. Fit and transform the data\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "print(\"Original Data:\\n\", df)\n",
    "print(\"\\nScaled Data (MinMaxScaler):\\n\", scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eb7063",
   "metadata": {},
   "source": [
    "#### Q.23) What is sklearn.preprocessing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55369294",
   "metadata": {},
   "source": [
    "Answer ->\n",
    "\n",
    "sklearn.preprocessing is a module in the Scikit-learn library that provides essential tools for cleaning, transforming, and preparing raw data so it can be effectively used by machine learning algorithms.\n",
    "\n",
    "Many machine learning models assume that the input data is clean, well-scaled, and in a numerical format. The functions in this module help you get your data into this required state. 🛠️\n",
    "\n",
    "Key Preprocessing Techniques\n",
    "* Scaling Features\n",
    "Scaling changes the range of your numerical data so that features with large values don't dominate the model's learning process. This is crucial for algorithms that are sensitive to the magnitude of features.\n",
    "\n",
    "StandardScaler: Scales data to have a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "MinMaxScaler: Scales data to a given range, typically between 0 and 1.\n",
    "\n",
    "* Encoding Categorical Features\n",
    "Machine learning models require numerical input, so categorical data (like text labels \"red,\" \"green,\" or \"blue\") must be converted into a numerical format.\n",
    "\n",
    "OneHotEncoder: Converts a categorical feature into multiple new binary (0/1) features.\n",
    "\n",
    "LabelEncoder: Converts each category into a unique integer (e.g., \"red\" -> 0, \"green\" -> 1).\n",
    "\n",
    "* Normalization\n",
    "Normalization is the process of scaling individual samples (rows) to have a unit norm (a length of 1). This is useful when the direction of the data matters more than its magnitude.\n",
    "\n",
    "Normalizer: Rescales each row of your data. This is different from scaling, which operates on columns (features).\n",
    "\n",
    "In summary, sklearn.preprocessing is the toolbox you use to make your raw data clean and structured, which is a critical step for building a high-performing machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef0fe72",
   "metadata": {},
   "source": [
    "#### Q.24) How do we split data for model fitting (training and testing) in Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ecf08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function from the library\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assume 'X' contains your features (e.g., a pandas DataFrame or NumPy array)\n",
    "# and 'y' contains your target variable (the labels or values you want to predict)\n",
    "\n",
    "# Example placeholder data:\n",
    "# X = your_features\n",
    "# y = your_target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Now you have four new datasets:\n",
    "# X_train: Features for training the model\n",
    "# y_train: Labels for training the model\n",
    "# X_test: Features for testing the model\n",
    "# y_test: Labels for testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8404ef6",
   "metadata": {},
   "source": [
    "Answer ->\n",
    "Explanation of the Parameters\n",
    "X, y: These are your full datasets. X is the data with the features used for prediction, and y is the target variable (what you are trying to predict).\n",
    "\n",
    "test_size=0.2: This argument determines the proportion of the dataset to allocate to the test set. Here, 0.2 means 20% of the data will be used for testing, and the remaining 80% will be used for training. This is a very common split, though 70/30 is also widely used.\n",
    "\n",
    "random_state=42: This is a crucial parameter for reproducibility. The train_test_split function randomly shuffles the data before splitting it. By setting a random_state to any integer (42 is just a popular convention), you ensure that you get the exact same split every time you run the code. This makes your results reproducible and easier to debug. If you omit it, you'll get a different random split each time.\n",
    "\n",
    "\n",
    "stratify=y (Optional but important): If you are working on a classification problem with an imbalanced dataset (e.g., 90% of samples are class A and 10% are class B), you should add the stratify=y argument. This ensures that the training and test sets have the same proportion of each class as the original dataset, which prevents biased evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd69dba",
   "metadata": {},
   "source": [
    "#### Q.25) Explain data encoding?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442e681b",
   "metadata": {},
   "source": [
    "Answer ->\n",
    "\n",
    "Data encoding is the process of converting categorical data (text labels) into a numerical format that a machine learning algorithm can understand and work with.\n",
    "\n",
    "Think of it as translating words into a language of numbers that a computer can process. Machine learning models are built on mathematics, so they require all input features to be numerical. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
